{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import ast\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for all figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '..'\n",
    "RESULTS_DIR = os.path.join(BASE_DIR,'cami2_benchmark', 'model_results', 'parsed_results') #v4 has c10 and c20 contamination threshold\n",
    "RESULTS_DIR_PHENO = os.path.join(BASE_DIR, \"phenotype_mil\", \"binning_results\", \"parsed_results\")\n",
    "\n",
    "OUT_DIR = os.path.join(BASE_DIR, 'figures')\n",
    "\n",
    "DATASET_ORDER = [\n",
    "    'airways_short',\n",
    "    'gastro_short',\n",
    "    'oral_short',\n",
    "    'urogenital_short',\n",
    "    'skin_short',\n",
    "    'marine_short',\n",
    "    'plant_short',\n",
    "    'metahit'\n",
    "]\n",
    "\n",
    "#main results\n",
    "MODELS = ['dnaberth_400kv2', 'dnaberth_2mv4','dnaberth_2mv5', 'dnaberts', 'dnabert2', 'tnf',  'dna2vec']\n",
    "MODEL_NAMES = ['DNABERT-H-400k', 'DNABERT-H-2M', 'DNABERT-H-2M-R', 'DNABERT-S', 'DNABERT-2', 'TNF', 'DNA2Vec']\n",
    "\n",
    "completeness_levels = ['>90%', '>80%', '>70%', '>60%', '>50%']\n",
    "colors = ['#005f5f', '#008c8c', '#66c2c2', '#a0e6e6', '#d9fafa']\n",
    "\n",
    "#other dnaberth versions\n",
    "# MODELS = ['dnaberth_400k', 'dnaberth_2mv1', 'dnaberth_2mv2', 'dnaberth_400kv2', 'dnaerth_2mv3', 'dnaberts', 'dnabert2', 'dnabert2random', 'tnf', 'tnfkernel', 'dna2vec']\n",
    "# MODEL_NAMES = ['DNABERT-H 400k', 'DNABERT-H 2MV1', 'DNABERT-H 2MV2', 'DNABERT-H 400kV2', 'DNABERT-H 2MV3' 'DNABERT-S', 'DNABERT-2', 'DNABERT2-Random', 'TNF', 'TNF-Kernel', 'DNA2Vec']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single CHECKM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_quality_report(file_path):\n",
    "    \"\"\"Parses a CheckM2 quality report and extracts completeness & contamination.\"\"\"\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "    df = df[df[\"Contamination\"] < 5]\n",
    "    return df[\"Completeness\"].values\n",
    "\n",
    "\n",
    "def process_all_reports(model_results_dir):\n",
    "    \"\"\"Walks through the model_results_dir to collect all models and datasets.\"\"\"\n",
    "    data = {}\n",
    "\n",
    "    for dataset in os.listdir(model_results_dir):\n",
    "        dataset_path = os.path.join(model_results_dir, dataset, \"checkm2\")\n",
    "        if not os.path.isdir(dataset_path):\n",
    "            continue\n",
    "\n",
    "        for model in os.listdir(dataset_path):\n",
    "            report_path = os.path.join(dataset_path, model, \"quality_report.tsv\")\n",
    "            if not os.path.isfile(report_path):\n",
    "                continue\n",
    "\n",
    "            completeness_values = parse_quality_report(report_path)\n",
    "            bin_counts = [\n",
    "                int(np.sum(completeness_values >= b)) for b in ['>90%', '>80%', '>70%', '>60%', '>50%']\n",
    "            ]\n",
    "\n",
    "            if dataset not in data:\n",
    "                data[dataset] = {}\n",
    "            data[dataset][model] = bin_counts\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(f'dnaberthv4/quality_report_.tsv')\n",
    "k = parse_quality_report(path)\n",
    "bin_counts = [\n",
    "            int(np.sum(k >= b)) for b in [90, 80, 70, 60, 50]\n",
    "]\n",
    "print(bin_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CheckM2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_DIR, 'parsed_checkm2_results.json'), 'r') as f:\n",
    "    checkm2_data = json.load(f)\n",
    "    \n",
    "na_metahit = ['vamb_results', 'taxvamb_results', 'comebin_results']\n",
    "if 'metahit' in checkm2_data:\n",
    "    for method in na_metahit:\n",
    "        if method not in checkm2_data['metahit']:\n",
    "            checkm2_data['metahit'][method] = [-1] * len(checkm2_data['metahit']['dnabert2_results'])\n",
    "            \n",
    "na_marine = ['comebin_results']\n",
    "if 'marine_short' in checkm2_data:\n",
    "    for method in na_marine:\n",
    "        if method not in checkm2_data['marine_short']:\n",
    "            checkm2_data['marine_short'][method] = [-1] * len(checkm2_data['marine_short']['dnabert2_results'])\n",
    "            \n",
    "\n",
    "results_to_remove = {'dnaberth_400k_results', 'dnaberth_2mv1_results', 'dnaberth_2mv2_results', 'dnabert2random_results', 'tnfkernel_results'}\n",
    "#results_to_remove = {'dnaberth_400k_results', 'dnaberth_2mv1_results', 'dnaberth_2mv2_results'} #for cami2appendix\n",
    "for dataset in checkm2_data.values():\n",
    "    for key in results_to_remove:\n",
    "        dataset.pop(key, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cami2_model_names = {\n",
    "    'vamb_results': 'VAMB',\n",
    "    'taxvamb_results': 'TaxVAMB',\n",
    "    'comebin_results': 'Comebin',\n",
    "    #'dnaberth_400k_results': 'DNABERT-H 400k',\n",
    "    #'dnaberth_2mv1_results': 'DNABERT-H 2MV1',\n",
    "    #'dnaberth_2mv2_results': 'DNABERT-H 2MV2',\n",
    "    'dnaberth_400kv2_results': 'DNABERT-H-400k',\n",
    "    'dnaberth_2mv4_results': 'DNABERT-H-2M',\n",
    "    'dnaberth_2mv5_results': 'DNABERT-H-2M-R',\n",
    "    'dnaberts_results': 'DNABERT-S',\n",
    "    'dnabert2_results': 'DNABERT-2',\n",
    "    'dnabert2random_results': 'DNABERT2-Random',\n",
    "    'tnf_results': 'TNF',\n",
    "    'tnfkernel_results': 'TNF-Kernel',\n",
    "    'dna2vec_results': 'DNA2Vec'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 4\n",
    "n_rows = int((len(DATASET_ORDER) + n_cols - 1) / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 6), constrained_layout=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "max_total = 0\n",
    "\n",
    "for idx, domain in enumerate(DATASET_ORDER):\n",
    "    methods = checkm2_data[domain]\n",
    "    \n",
    "    # Filter and sort method names based on custom order\n",
    "    method_names = [m for m in cami2_model_names.keys() if m in methods]\n",
    "    y_pos = list(range(len(method_names)))\n",
    "    \n",
    "    left = [0] * len(method_names)\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    for i, comp in enumerate(completeness_levels):\n",
    "        if domain not in ['marine_short','metahit']:\n",
    "            if i == 0:\n",
    "                values = [methods[m][i] for m in method_names]\n",
    "            else:\n",
    "                values = [methods[m][i] - methods[m][i - 1] for m in method_names]\n",
    "            \n",
    "            ax.barh(y_pos, values, left=left, color=colors[i], edgecolor='black', height=0.6)\n",
    "            left = [l + v for l, v in zip(left, values)]\n",
    "            \n",
    "        elif domain in ['marine_short','metahit']:\n",
    "            values = []\n",
    "            for m in method_names:\n",
    "                if methods[m][0] == -1:\n",
    "                    values.append(None)\n",
    "                elif i == 0:\n",
    "                    values.append(methods[m][i])\n",
    "                else:\n",
    "                    values.append(methods[m][i] - methods[m][i - 1])\n",
    "\n",
    "            for j, val in enumerate(values):\n",
    "                if val is not None:\n",
    "                    ax.barh(j, val, left=left[j], color=colors[i], edgecolor=\"black\", height=0.6)\n",
    "                    left[j] += val\n",
    "\n",
    "    # For metahit: show \"N/A\" if method data is -1\n",
    "    if domain in ['metahit']:\n",
    "        for j, m in enumerate(method_names):\n",
    "            if methods[m][0] == -1:\n",
    "                ax.text(1.2, j+0.4, \"N/A\", va=\"center\", ha=\"center\", fontsize=10, color=\"black\", fontstyle=\"italic\")\n",
    "    if domain in ['marine_short']:\n",
    "        for j, m in enumerate(method_names):\n",
    "            if methods[m][0] == -1:\n",
    "                ax.text(1.7, j, \"N/A\", va=\"center\", ha=\"center\", fontsize=10, color=\"black\", fontstyle=\"italic\")\n",
    "\n",
    "\n",
    "    ax.set_title(domain.replace('_short', '').capitalize())\n",
    "\n",
    "    if idx % n_cols == 0:\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels([cami2_model_names.get(m, m.replace('_results', '')) for m in method_names])\n",
    "    else:\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels([])\n",
    "        ax.tick_params(left=False)\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "    max_total = max(max_total, max(left))\n",
    "\n",
    "for i in range(len(DATASET_ORDER), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "legend_labels = [f'{level}' for level in completeness_levels]  # Do NOT reverse\n",
    "legend_patches = [Patch(facecolor=c, edgecolor='black', label=l) for c, l in zip(colors, legend_labels)]\n",
    "\n",
    "fig.legend(handles=legend_patches, loc='center left', bbox_to_anchor=(0.99, 0.5),\n",
    "           title='Completeness', frameon=False, handletextpad=1, labelspacing=0.7, fontsize=11, title_fontsize=12)\n",
    "\n",
    "fig.text(0.55, -0.03, \"Bins (< 5% contamination)\", fontsize=12, ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"cami2_main.svg\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_DIR_PHENO, 'parsed_checkm2_results.json'), 'r') as f:\n",
    "    checkm2_data_pheno = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "cami2_model_names_pheno = {\n",
    "    'vamb_results': 'VAMB',\n",
    "    'dnaberth_2mv4_results': 'DNABERT-H-2M',\n",
    "    'dnaberts_results': 'DNABERT-S'\n",
    "}\n",
    "\n",
    "dataset_namemap_pheno = {'UNSEEN': 'WEGOVY',\n",
    "                         'T2D-EW': 'T2D-EUW'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkm2_data_pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(7, 2.5), constrained_layout=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "max_total = 0\n",
    "\n",
    "for idx, domain in enumerate(['T2D-EW', 'UNSEEN']):\n",
    "    methods = checkm2_data_pheno[domain]\n",
    "    \n",
    "    # Filter and sort method names based on custom order\n",
    "    method_names = [m for m in cami2_model_names_pheno.keys() if m in methods]\n",
    "    y_pos = list(range(len(method_names)))\n",
    "    \n",
    "    left = [0] * len(method_names)\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    for i, comp in enumerate(completeness_levels):\n",
    "\n",
    "        if i == 0:\n",
    "            values = [methods[m][i] for m in method_names]\n",
    "        else:\n",
    "            values = [methods[m][i] - methods[m][i - 1] for m in method_names]\n",
    "        \n",
    "        ax.barh(y_pos, values, left=left, color=colors[i], edgecolor='black', height=0.6)\n",
    "        left = [l + v for l, v in zip(left, values)]\n",
    "            \n",
    "\n",
    "    ax.set_title(dataset_namemap_pheno[domain])\n",
    "\n",
    "    if idx % 2 == 0:\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels([cami2_model_names.get(m, m.replace('_results', '')) for m in method_names])\n",
    "    else:\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels([])\n",
    "        ax.tick_params(left=False)\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "    max_total = max(max_total, max(left))\n",
    "\n",
    "for i in range(len(DATASET_ORDER), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "legend_labels = [f'{level}' for level in completeness_levels]  # Do NOT reverse\n",
    "legend_patches = [Patch(facecolor=c, edgecolor='black', label=l) for c, l in zip(colors, legend_labels)]\n",
    "\n",
    "fig.legend(handles=legend_patches, loc='center left', bbox_to_anchor=(0.99, 0.5),\n",
    "           title='Completeness', frameon=False, handletextpad=1, labelspacing=0.7, fontsize=10, title_fontsize=11)\n",
    "\n",
    "fig.text(0.55, -0.03, \"Bins (< 5% contamination)\", fontsize=11, ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(os.path.join(OUT_DIR, \"cami2_pheno.svg\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_DIR, 'parsed_knn_histograms.json'), 'r') as f:\n",
    "    knn_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_histogram_data(dataset_dict):\n",
    "    \"\"\"\n",
    "    Adds a 0 and 1 to the start and end of the pairsim_vector and bin_vector\n",
    "    \"\"\"\n",
    "    \n",
    "    for dataset_name, models in dataset_dict.items():\n",
    "        for model_name, model_data in models.items():\n",
    "            # Modify pairsim_vector by adding 0 at the start and 1 at the end\n",
    "            if \"pairsim_vector\" in model_data:\n",
    "                model_data[\"pairsim_vector\"] = [0] + model_data[\"pairsim_vector\"] + [1]\n",
    "            \n",
    "            # Modify bin_vector by adding 0 at both the start and end\n",
    "            if \"bin_vector\" in model_data:\n",
    "                model_data[\"bin_vector\"] = [0] + model_data[\"bin_vector\"] + [0]\n",
    "\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_data = {k: knn_data[k] for k in DATASET_ORDER if k in knn_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(dataset_dict, selected_models: list, selected_MODEL_NAMES:list, save_name:str):\n",
    "    \"\"\"\n",
    "    Plots histograms for the selected models of each dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_dict (dict): Dictionary where the key is the dataset name and value is a \n",
    "                             dictionary of models and associated histogram data.\n",
    "    \"\"\"\n",
    "    dataset_dict = modify_histogram_data(dataset_dict)\n",
    "    color_thres = 'darkred'\n",
    "    n_datasets = len(dataset_dict)\n",
    "    n_models = len(selected_models)\n",
    "\n",
    "    if len(selected_models) == 3:\n",
    "        fig, axes = plt.subplots(n_datasets, n_models, figsize=(10, 1.7 * n_datasets), squeeze=False)\n",
    "    else:\n",
    "        fig, axes = plt.subplots(n_datasets, n_models, figsize=(4, 1.7 * n_datasets), squeeze=False)\n",
    "\n",
    "    for i, (dataset_name, models) in enumerate(dataset_dict.items()):\n",
    "        for j, (model_name, model_namepretty) in enumerate(zip(selected_models, selected_MODEL_NAMES)):\n",
    "\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            x_data = models[model_name].get(\"pairsim_vector\", None)\n",
    "            y_data = models[model_name].get(\"bin_vector\", None)\n",
    "            threshold = models[model_name].get(\"knn_threshold\", None)\n",
    "            k = models[model_name].get(\"k\", None)\n",
    "            p = models[model_name].get(\"p\", None)\n",
    "\n",
    "            #histogram\n",
    "            ax.plot(x_data, y_data, color='steelblue', linestyle='-', linewidth=2)\n",
    "            ax.fill_between(x_data, y_data, color='steelblue', alpha=0.3)\n",
    "\n",
    "            # Add k, p box\n",
    "            ax.text(\n",
    "                0.04, 0.96, f'k={k}, p={p}', \n",
    "                transform=ax.transAxes, fontsize=10, verticalalignment='top', horizontalalignment='left',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', edgecolor='gray', alpha=0.6)\n",
    "            )\n",
    "\n",
    "            # Threshold line and annotation\n",
    "            ax.axvline(threshold, color=color_thres, linestyle='--', label=f'Threshold: {threshold:.2f}')\n",
    "            if model_name in ['aa']:\n",
    "                ax.text(threshold + 0.04, 0.8 * max(ax.get_ylim()), f'{threshold:.2f}', color=color_thres, fontsize=11, ha='left')\n",
    "                ax.plot([threshold + 0.04, threshold + 0.04 + 0.11], [0.78 * max(ax.get_ylim())] * 2, color=color_thres, lw=1)\n",
    "            else:\n",
    "                ax.text(threshold - 0.09, 0.8 * max(ax.get_ylim()), f'{threshold:.2f}', color=color_thres, fontsize=11, ha='center')\n",
    "                ax.plot([threshold - 0.04, threshold - 0.04 - 0.11], [0.78 * max(ax.get_ylim())] * 2, color=color_thres, lw=1)\n",
    "\n",
    "            # Y-axis formatting\n",
    "            y_min, y_max = ax.get_ylim()\n",
    "            y_ticks = np.linspace(y_min, y_max, 4)\n",
    "            ax.set_yticks(y_ticks)\n",
    "            ax.set_yticklabels([f'{tick / 100:.5f}' for tick in y_ticks])\n",
    "            ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "            # Add column titles\n",
    "            if i == 0:\n",
    "                ax.set_title(model_namepretty, fontsize=13, pad=12)\n",
    "\n",
    "        # Add row labels on the far left\n",
    "        #fig.text(-0.01, (1 - (i + 0.5) / n_datasets), dataset_name.replace('_short','').capitalize(), ha='left', va='center', fontsize=13, rotation='vertical')\n",
    "        \n",
    "        # Add row labels directly on the y-axis of the leftmost subplot\n",
    "        row_ax = axes[i, 0]\n",
    "        row_ax.annotate(\n",
    "            dataset_name.replace('_short','').capitalize(),\n",
    "            xy=(-0.15, 0.5), xycoords='axes fraction',\n",
    "            xytext=(-row_ax.yaxis.labelpad - 30, 0),\n",
    "            textcoords='offset points',\n",
    "            ha='right', va='center', fontsize=13, rotation='vertical'\n",
    "        )\n",
    "\n",
    "\n",
    "    fig.supxlabel('Similarity', fontsize=16)\n",
    "    fig.supylabel('Density', fontsize=16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, f\"{save_name}\"), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(knn_data, MODELS[:3], MODEL_NAMES[:3], 'histogram_1.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(knn_data, MODELS[3:6], MODEL_NAMES[3:6], 'histogram_2.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(knn_data, MODELS[6:], MODEL_NAMES[6:], 'histogram_3.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_heatmaps = {\n",
    "    #'vamb': 'VAMB',\n",
    "    #'taxvamb': 'TaxVAMB',\n",
    "    #'comebin': 'Comebin',\n",
    "    #'dnaberth': 'DNABERT-H 400k',\n",
    "    #'dnaberth_2mv1': 'DNABERT-H 2MV1',\n",
    "    #'dnaberth_2mv2': 'DNABERT-H 2MV2',\n",
    "    'dnaberth_400kv2': 'DNABERT-H-400k',\n",
    "    'dnaberth_2mv4': 'DNABERT-H-2M',\n",
    "    'dnaberth_2mv5': 'DNABERT-H-2M-R',\n",
    "    'dnaberts': 'DNABERT-S',\n",
    "    'dnabert2': 'DNABERT-2',\n",
    "    #'dnabert2random': 'DNABERT2-Random',\n",
    "    'tnf': 'TNF',\n",
    "    #'tnfkernel': 'TNF-Kernel',\n",
    "    'dna2vec': 'DNA2Vec'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps = pd.read_csv(os.path.join(RESULTS_DIR, 'heatmaps.csv'), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmaps(results_df: pd.DataFrame, models_to_plot: list[str], max_plots=8, datasets_to_plot=None):\n",
    "    \"\"\"\n",
    "    For each model in `models_to_plot`, plots up to 8 heatmaps (for datasets) in a 4x2 grid per figure.\n",
    "    X and Y axes are swapped (K on x-axis, Percentile on y-axis).\n",
    "    Dataset names are cleaned (_short removed and capitalized).\n",
    "    \"\"\"\n",
    "\n",
    "    if datasets_to_plot is None:\n",
    "        datasets_to_plot = DATASET_ORDER\n",
    "    else:\n",
    "        datasets_to_plot = [ds for ds in DATASET_ORDER if ds in datasets_to_plot]\n",
    "\n",
    "    results_df['heatmap'] = results_df['heatmap'].apply(\n",
    "        lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    "    for model in models_to_plot:\n",
    "        print(f\"PLOT FOR ------{model}\")\n",
    "        model_df = results_df[(results_df['model'] == model) & (results_df['dataset'].isin(datasets_to_plot))]\n",
    "        model_df['dataset'] = pd.Categorical(model_df['dataset'], categories=datasets_to_plot, ordered=True)\n",
    "        model_df = model_df.sort_values('dataset')\n",
    "\n",
    "        n_plots = min(len(model_df), max_plots)\n",
    "        n_cols = 4\n",
    "        n_rows = math.ceil(n_plots / n_cols)\n",
    "\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(4.2 * n_cols, 2.3 * n_rows))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        # Create a new axis for the color bar (to the right of the last plot)\n",
    "        cbar_ax = fig.add_axes([0.91, 0.15, 0.02, 0.7])  # Adjust the position for color bar\n",
    "\n",
    "        # Find the global min and max for color scale within the model\n",
    "        min_val = float('inf')\n",
    "        max_val = float('-inf')\n",
    "\n",
    "        # Loop through each dataset in the model and calculate the global min and max values\n",
    "        for _, row in model_df.head(max_plots).iterrows():\n",
    "            heatmap_dict = row['heatmap']\n",
    "            df = pd.DataFrame(heatmap_dict)\n",
    "            df.index = df.index.astype(int)  # Percentiles\n",
    "            df.columns = df.columns.astype(int)  # Ks\n",
    "\n",
    "            df = df.sort_index(axis=0, ascending=False)  # Reverse the order of percentiles (Y-axis)\n",
    "            df = df.sort_index(axis=1)  # K (X-axis)\n",
    "\n",
    "            # Update min and max values for color scale\n",
    "            min_val = min(min_val, df.values.min())\n",
    "            max_val = max(max_val, df.values.max())\n",
    "\n",
    "        # Loop over each subplot to plot the heatmap with consistent color scale within the model\n",
    "        for i, (_, row) in enumerate(model_df.head(max_plots).iterrows()):\n",
    "            heatmap_dict = row['heatmap']\n",
    "            df = pd.DataFrame(heatmap_dict)\n",
    "            df.index = df.index.astype(int)  # Percentiles\n",
    "            df.columns = df.columns.astype(int)  # Ks\n",
    "\n",
    "            df = df.sort_index(axis=0, ascending=False)  # Reverse the order of percentiles (Y-axis)\n",
    "            df = df.sort_index(axis=1)  # K (X-axis)\n",
    "\n",
    "            pretty_name = row['dataset'].replace('_short', '').capitalize()\n",
    "\n",
    "            # Plot the heatmap for each dataset with consistent color scale within the model\n",
    "            fmt_func = np.vectorize(lambda x: f\"{x:.2f}\".lstrip(\"0\") if 0 <= x < 1 else f\"{x:.2f}\")\n",
    "\n",
    "            sns.heatmap(\n",
    "                df.values,\n",
    "                annot=fmt_func(df.values),\n",
    "                fmt=\"\",\n",
    "                cmap=\"flare\",\n",
    "                cbar=True,\n",
    "                linewidths=0.5,\n",
    "                xticklabels=df.columns,\n",
    "                yticklabels=df.index,\n",
    "                ax=axes[i],\n",
    "                cbar_ax=cbar_ax,\n",
    "                vmin=min_val,\n",
    "                vmax=max_val\n",
    "            )\n",
    "            axes[i].set_title(pretty_name)\n",
    "            axes[i].tick_params(axis='y', rotation=0)\n",
    "\n",
    "            # Set Y-axis labels only for the 1st and 5th plot (0-indexed 0 and 4)\n",
    "            if i != 0 and i != 4:\n",
    "                axes[i].set_yticklabels([])\n",
    "\n",
    "            # Set X-axis labels only for the 5th, 6th, 7th, and 8th plot (0-indexed 4, 5, 6, 7)\n",
    "            if i < 4 or i > 7:\n",
    "                axes[i].set_xticklabels([])\n",
    "\n",
    "        # Hide unused subplots\n",
    "        for j in range(n_plots, len(axes)):\n",
    "            axes[j].axis('off')\n",
    "\n",
    "        # Common x and y labels\n",
    "        fig.suptitle(f\"{model_names_heatmaps[model]}\", fontsize=15, y=0.92)\n",
    "        fig.supxlabel(\"K Neighbors\", fontsize=12)\n",
    "        fig.supylabel(\"Percentile (P)\", fontsize=12, x=0)  # Move the Y-axis label further left\n",
    "        \n",
    "        # Adjust layout for common color bar\n",
    "        plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n",
    "        plt.savefig(os.path.join(OUT_DIR, \"heatmaps_knn\", f'{model}.svg'), bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmaps(heatmaps, models_to_plot=MODELS)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contig length histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_DIR, 'parsed_contig_lengths.json'), 'r') as f:\n",
    "    contig_data_cami2 = json.load(f)\n",
    "contig_data_cami2 = {key: contig_data_cami2[key] for key in DATASET_ORDER if key in contig_data_cami2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_DIR, 'parsed_contig_lengths_mil.json'), 'r') as f:\n",
    "    contig_data_mil = json.load(f)\n",
    "contig_data_mil = {key: contig_data_mil[key] for key in ['T2D-EW_PRJEB1786', 'UNSEEN_BIO'] if key in contig_data_mil}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_data_all = {**contig_data_cami2, **contig_data_mil}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_cols = 5\n",
    "n_rows = 2\n",
    "min_length = 2000\n",
    "highlight_threshold = 60000  # threshold to count lengths above\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 4.5), constrained_layout=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (dataset, lengths) in enumerate(contig_data_all.items()):\n",
    "    ax = axes[idx]\n",
    "    # Ensure lengths is a numpy array for min/max operations\n",
    "    arr = np.array(lengths)\n",
    "\n",
    "    # Compute log-spaced bins\n",
    "    min_edge = max(arr.min(), min_length)\n",
    "    max_edge = arr.max()\n",
    "    bins = np.logspace(np.log10(min_edge), np.log10(max_edge), 40)\n",
    "\n",
    "    # Plot histogram on log scale\n",
    "    ax.hist(arr, bins=bins, color='skyblue', edgecolor='black')\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "    # Count how many lengths exceed the threshold\n",
    "    count_above = np.sum(arr >= highlight_threshold)\n",
    "\n",
    "    if dataset in DATASET_ORDER:\n",
    "        ax.set_title(dataset.replace('_short', '').capitalize())\n",
    "    else:\n",
    "        name_map = {'UNSEEN_BIO': 'WEGOVY', 'T2D-EW_PRJEB1786': 'T2D-EUW'}\n",
    "        ax.set_title(name_map.get(dataset, dataset))\n",
    "    # Display count above threshold\n",
    "    ax.text(\n",
    "        0.95, 0.95,\n",
    "        f'>60K: {count_above} ({count_above / len(arr) * 100:.1f}%)',\n",
    "        ha='right', va='top', transform=ax.transAxes,\n",
    "        fontsize=9, color='dimgrey'\n",
    "    )\n",
    "\n",
    "    # Format ticks: use log ticks\n",
    "    ax.xaxis.set_major_locator(plt.LogLocator(base=10.0, numticks=5))\n",
    "    ax.xaxis.set_minor_locator(plt.LogLocator(base=10.0, subs='auto', numticks=10))\n",
    "    ax.xaxis.set_minor_formatter(plt.NullFormatter())\n",
    "\n",
    "# Global labels\n",
    "fig.text(0.5, -0.015, 'Contig Length (log scale)', ha='center', va='center', fontsize=12)\n",
    "fig.text(-0.01, 0.5, 'Frequency', ha='center', va='center', rotation='vertical', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, 'seq_len_hist_log.svg'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot setup\n",
    "n_cols = 1\n",
    "n_rows = 2\n",
    "percentile = 98\n",
    "min_length = 2000\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 5), constrained_layout=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (dataset, lengths) in enumerate(contig_data_mil.items()):\n",
    "    ax = axes[idx]\n",
    "    top_1_percentile = np.percentile(lengths, 99)\n",
    "    top_1_count = sum(l > top_1_percentile for l in lengths)\n",
    "    print(dataset, top_1_count)\n",
    "    ax.hist(lengths, bins=40, color='skyblue', range=(min_length, top_1_percentile), edgecolor='black')\n",
    "    ax.set_title(dataset.replace('_short','').capitalize())\n",
    "    ax.text(0.95, 0.95, f'Top {100-percentile}%: n={top_1_count}', ha='right', va='top', transform=ax.transAxes, fontsize=9, color='grey') \n",
    "    ticks = np.linspace(min_length, top_1_percentile, 4)  \n",
    "    ticks = np.round(ticks / 1000) * 1000\n",
    "    ax.set_xticks(ticks)\n",
    "    \n",
    "fig.text(0.5, 0.0, 'Contig Length', ha='center', va='center', fontsize=12)  # X-axis label\n",
    "fig.text(-0.01, 0.5, 'Frequency', ha='center', va='center', rotation='vertical', fontsize=12) \n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(os.path.join(OUT_DIR, 'seq_len_hist.svg'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot setup\n",
    "n_cols = 4\n",
    "n_rows = 2\n",
    "percentile = 98\n",
    "min_length = 2000\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 5), constrained_layout=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (dataset, lengths) in enumerate(contig_data_cami2.items()):\n",
    "    ax = axes[idx]\n",
    "    top_1_percentile = np.percentile(lengths, 99)\n",
    "    top_1_count = sum(l > top_1_percentile for l in lengths)\n",
    "    print(dataset, top_1_count)\n",
    "    ax.hist(lengths, bins=40, color='skyblue', range=(min_length, top_1_percentile), edgecolor='black')\n",
    "    ax.set_title(dataset.replace('_short','').capitalize())\n",
    "    ax.text(0.95, 0.95, f'Top {100-percentile}%: n={top_1_count}', ha='right', va='top', transform=ax.transAxes, fontsize=9, color='grey') \n",
    "    ticks = np.linspace(min_length, top_1_percentile, 4)  \n",
    "    ticks = np.round(ticks / 1000) * 1000\n",
    "    ax.set_xticks(ticks)\n",
    "    \n",
    "fig.text(0.5, 0.0, 'Contig Length', ha='center', va='center', fontsize=12)  # X-axis label\n",
    "fig.text(-0.01, 0.5, 'Frequency', ha='center', va='center', rotation='vertical', fontsize=12) \n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(os.path.join(OUT_DIR, 'seq_len_hist.svg'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomorative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHENO_RESULTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggd = np.load(\"agglomorative_dnaberts_T2D-EW_agglomorative_data.npz\")\n",
    "aggl = aggd[\"labels\"]\n",
    "agge = aggd['embedding']\n",
    "aggn = aggd[\"n_clusters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors as mcolors\n",
    "from colorsys import hls_to_rgb\n",
    "\n",
    "def get_distinct_colors(n):\n",
    "    \"\"\"\n",
    "    Generate n visually distinct colors using HLS color space.\n",
    "    \"\"\"\n",
    "    colors = []\n",
    "    for i in np.linspace(0, 1, n, endpoint=False):\n",
    "        h = i  # Hue\n",
    "        l = 0.5 + np.random.rand() * 0.1  # Lightness\n",
    "        s = 0.6 + np.random.rand() * 0.2  # Saturation\n",
    "        r, g, b = hls_to_rgb(h, l, s)\n",
    "        colors.append((r, g, b))\n",
    "    return colors\n",
    "\n",
    "# Assuming 'aggl' contains cluster labels and 'agge' contains the 2D t-SNE embeddings\n",
    "# 'aggn' represents the number of clusters\n",
    "\n",
    "colors = get_distinct_colors(aggn)\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "ax = plt.gca()\n",
    "\n",
    "# Plot each cluster with a unique color\n",
    "for lbl in np.unique(aggl):\n",
    "    mask = aggl == lbl\n",
    "    ax.scatter(\n",
    "        agge[mask, 0],\n",
    "        agge[mask, 1],\n",
    "        label=f\"Cluster {lbl}\",\n",
    "        s=20,\n",
    "        alpha=0.8,\n",
    "        edgecolors='b',\n",
    "        linewidth=0.5,\n",
    "        color=colors[lbl]\n",
    "    )\n",
    "\n",
    "# Set plot title\n",
    "ax.set_title(f\"Agglomerative Clustering (n_clusters={aggn}, linkage='ward')\")\n",
    "\n",
    "# Remove axis labels and ticks\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Hide all spines (borders)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "# Position the legend outside the plot\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1), title=\"Clusters\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-SNE on Hausdorff Distances with GTDB Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BINLOOPUP_DIR = os.path.join('..','phenotype_mil', 'mil_results')\n",
    "#BINLOOKUP_DATASETS = ['T2D-EW', 'UNSEEN']\n",
    "BINLOOKUP_DATASETS = ['T2D-EW']\n",
    "BINLOOPUP_MODELS = ['dnaberts', 'dnaberth_2mv4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_prefixes = {\n",
    "    'd__': 'domain',\n",
    "    'p__': 'phylum',\n",
    "    'c__': 'class',\n",
    "    'o__': 'order',\n",
    "    'f__': 'family',\n",
    "    'g__': 'genus',\n",
    "    's__': 'species',\n",
    "}\n",
    "\n",
    "\n",
    "def split_taxonomy(tax_str):\n",
    "    # initialize all ranks to NaN\n",
    "    out = {v: None for v in rank_prefixes.values()}\n",
    "    for part in tax_str.split(';'):\n",
    "        for prefix, rank in rank_prefixes.items():\n",
    "            if part.startswith(prefix):\n",
    "                out[rank] = part[len(prefix):] or None\n",
    "                break\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_data = {}\n",
    "\n",
    "for dataset in BINLOOKUP_DATASETS:\n",
    "    for model in BINLOOPUP_MODELS:\n",
    "        print(model)\n",
    "        path = os.path.join(BINLOOPUP_DIR, dataset, f\"{model}_binlookup\")\n",
    "        print(path)\n",
    "        hausdorff_path = os.path.join(path, f\"{model}_{dataset}.npz\")\n",
    "        lookup_path = os.path.join(path, 'gtdbtk.bac120.summary.tsv')\n",
    "    \n",
    "        \n",
    "        hausdorff_npz  = np.load(hausdorff_path)\n",
    "        hausdorff_dist = hausdorff_npz[\"distance_matrix\"]            \n",
    "        hausdorff_cluster_names  = hausdorff_npz[\"cluster_names\"]        \n",
    "        \n",
    "        binlookup = pd.read_csv(lookup_path, sep=\"\\t\")\n",
    "        binlookup = binlookup.rename(columns={\"user_genome\": \"cluster_names\"})\n",
    "        binlookup['cluster_names'] = binlookup['cluster_names'].astype(str)\n",
    "        tax_df = binlookup['classification'].apply(split_taxonomy).apply(pd.Series)\n",
    "        binlookup = pd.concat([binlookup, tax_df], axis=1)\n",
    "        \n",
    "        first_two = [\"cluster_names\", \"classification\"]  \n",
    "        tax_ranks = [\"domain\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\"]\n",
    "        rest = [c for c in binlookup.columns\n",
    "                if c not in first_two + tax_ranks]\n",
    "        binlookup = binlookup[first_two + tax_ranks + rest]\n",
    "        \n",
    "        binlookup = binlookup[~binlookup['classification'].isin(['Unclassified Bacteria', 'Unclassified'])]\n",
    "    \n",
    "    \n",
    "        mask = np.isin(hausdorff_cluster_names, binlookup['cluster_names'].values)\n",
    "        filtered_names   = hausdorff_cluster_names[mask]\n",
    "        filtered_matrix  = hausdorff_dist[np.ix_(mask, mask)]\n",
    "        \n",
    "        # reorder binlookup to the same filtered order\n",
    "        binlookup = (\n",
    "            binlookup\n",
    "            .set_index(\"cluster_names\")\n",
    "            .loc[filtered_names]\n",
    "            .reset_index()\n",
    "        )\n",
    "        assert np.array_equal(filtered_names, binlookup[\"cluster_names\"].to_numpy())\n",
    "        assert len(filtered_names) == filtered_matrix.shape[0] == binlookup.shape[0]\n",
    "\n",
    "        lookup_data[f\"{dataset}_{model}\"] = {\n",
    "            \"hausdorff\": {\n",
    "                \"distances\": filtered_matrix,\n",
    "                \"cluster_names\": filtered_names\n",
    "            },\n",
    "            \"binlookup\": binlookup\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranks = [\"phylum\", \"class\", \"order\", \"family\", \"genus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster import hierarchy as sch\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# ----------------------------------------\n",
    "# Configuration\n",
    "# ----------------------------------------\n",
    "ranks = [\"class\", \"order\"]\n",
    "rank_palettes = {\n",
    "    \"class\": \"Set3\",\n",
    "    \"order\": \"pastel\"\n",
    "}\n",
    "\n",
    "# Map your lookup_data keys to pretty titles\n",
    "title_map = {\n",
    "    \"T2D-EW_dnaberts\": \"DNABERT-S\",\n",
    "    \"T2D-EW_dnaberth_2mv4\": \"DNABERT-H-2M\",\n",
    "    # add more key â†’ title mappings here...\n",
    "}\n",
    "\n",
    "# ----------------------------------------\n",
    "# Shared setup: build global_luts & counts\n",
    "# ----------------------------------------\n",
    "global_luts = {}\n",
    "rank_label_counts = {}\n",
    "for rank in ranks:\n",
    "    all_labels = []\n",
    "    for data in lookup_data:\n",
    "        all_labels.extend(lookup_data[data][\"binlookup\"][rank].dropna().values)\n",
    "    cnts = Counter(all_labels)\n",
    "    rank_label_counts[rank] = cnts\n",
    "    labels_sorted = [lab for lab,_ in cnts.most_common()]\n",
    "    pal = sns.color_palette(rank_palettes[rank], n_colors=len(labels_sorted))\n",
    "    global_luts[rank] = {lab: pal[i] for i, lab in enumerate(labels_sorted)}\n",
    "\n",
    "# ----------------------------------------\n",
    "# Plot each dataset separately\n",
    "# ----------------------------------------\n",
    "for data_key in lookup_data:\n",
    "    title = title_map.get(data_key, data_key)\n",
    "    print(f\"Number of clusters in {title}: {lookup_data[data_key]['hausdorff']['distances'].shape[0]}\")\n",
    "    print(title)\n",
    "    D = lookup_data[data_key][\"hausdorff\"][\"distances\"]\n",
    "    binlookup = lookup_data[data_key][\"binlookup\"]\n",
    "\n",
    "    # 1) Hierarchical clustering\n",
    "    ac = AgglomerativeClustering(\n",
    "        n_clusters=40, metric='euclidean', linkage='ward',\n",
    "        compute_full_tree=True, compute_distances=True\n",
    "    )\n",
    "    ac.fit(D)\n",
    "\n",
    "    # 2) Build linkage for dendrogram\n",
    "    n_leaves = D.shape[0]\n",
    "    children, dists = ac.children_, ac.distances_\n",
    "    counts = np.zeros(children.shape[0], dtype=int)\n",
    "    for i, (l, r) in enumerate(children):\n",
    "        lc = 1 if l < n_leaves else counts[l - n_leaves]\n",
    "        rc = 1 if r < n_leaves else counts[r - n_leaves]\n",
    "        counts[i] = lc + rc\n",
    "    linkage = np.column_stack([children, dists, counts]).astype(float)\n",
    "\n",
    "    # 3) Determine top-10 orders for coloring\n",
    "    top10_orders = [o for o, _ in rank_label_counts[\"order\"].most_common(10)]\n",
    "    order_lut = {o: global_luts[\"order\"][o] for o in top10_orders}\n",
    "\n",
    "    # 4) Make figure\n",
    "    fig = plt.figure(figsize=(8, 6.5))\n",
    "    gs = fig.add_gridspec(1, len(ranks) + 2,\n",
    "                          width_ratios=[1] + [0.30]*len(ranks) + [5],\n",
    "                          wspace=0.02)\n",
    "\n",
    "    # 5) Dendrogram\n",
    "    ax_den = fig.add_subplot(gs[0, 0])\n",
    "    dendro = sch.dendrogram(\n",
    "        linkage, orientation=\"left\", ax=ax_den,\n",
    "        no_labels=True, color_threshold=0,\n",
    "        above_threshold_color=\"slategrey\"\n",
    "    )\n",
    "    ax_den.invert_yaxis()\n",
    "    ax_den.axis(\"off\")\n",
    "    leaf_order = dendro[\"leaves\"]\n",
    "\n",
    "    # 6) Taxonomic stripes\n",
    "    for i, rank in enumerate(ranks):\n",
    "        vals = binlookup[rank].values[leaf_order]\n",
    "        if rank == \"order\":\n",
    "            colors = [order_lut.get(v, (0.8,0.8,0.8)) for v in vals]\n",
    "        else:\n",
    "            lut = global_luts[rank]\n",
    "            colors = [lut.get(v, (0.9,0.9,0.9)) for v in vals]\n",
    "\n",
    "        ax_bar = fig.add_subplot(gs[0, i + 1])\n",
    "        ax_bar.imshow(np.array(colors).reshape(-1, 1, 3), aspect=\"auto\")\n",
    "        ax_bar.set_xticks([]); ax_bar.set_yticks([])\n",
    "\n",
    "        ax_bar.set_xlabel(\n",
    "            rank.capitalize(),\n",
    "            fontsize=10,\n",
    "            labelpad=4,\n",
    "            rotation=90,\n",
    "            fontweight=\"bold\",\n",
    "            ha=\"center\"\n",
    "        )\n",
    "\n",
    "    # 7) Heatmap (only add colorbar if DNABERT-S)\n",
    "    ax_hm = fig.add_subplot(gs[0, -1])\n",
    "    D2 = D[np.ix_(leaf_order, leaf_order)]\n",
    "    show_cb = (title == \"DNABERT-S\")\n",
    "    sns.heatmap(\n",
    "        D2, ax=ax_hm, cmap=\"magma\",\n",
    "        xticklabels=False, yticklabels=False,\n",
    "        cbar=False,\n",
    "        #cbar_kws={\"label\": \"Hausdorff distance\"} if show_cb else {}\n",
    "    )\n",
    "    #ax_hm.set_title(title, fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, f\"heat_{title}_.svg\"), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    if title == \"DNABERT-S\":\n",
    "        fig_cb, ax_cb = plt.subplots(figsize=(1.0, 5))  # narrow and tall\n",
    "        fig_cb.subplots_adjust(left=0.5)\n",
    "\n",
    "        norm = plt.Normalize(vmin=np.min(D2), vmax=np.max(D2))\n",
    "        sm = plt.cm.ScalarMappable(cmap=\"magma\", norm=norm)\n",
    "        sm.set_array([])\n",
    "\n",
    "        cbar = fig_cb.colorbar(sm, cax=ax_cb, orientation=\"vertical\")\n",
    "        cbar.set_label(\"Hausdorff distance\", fontsize=11)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"heat_legend.svg\"), bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "    if title == \"DNABERT-H-2M\":\n",
    "       for rank in ranks:\n",
    "            most_common = rank_label_counts[rank].most_common(10)\n",
    "            labels = [label for label, count in most_common]\n",
    "            counts = [count for label, count in most_common]\n",
    "\n",
    "            # Get colors from global LUT, fallback to gray if missing\n",
    "            lut = global_luts[rank]\n",
    "            colors = [lut.get(label, (0.9, 0.9, 0.9)) for label in labels]\n",
    "\n",
    "            # Create legend patches with counts in label\n",
    "            patches = [\n",
    "                Patch(color=colors[i], label=f\"{labels[i]} ({counts[i]})\")\n",
    "                for i in range(len(labels))\n",
    "            ]\n",
    "\n",
    "            # Create separate legend figure\n",
    "            fig_legend, ax_legend = plt.subplots(figsize=(2, max(2, 0.3 * len(patches))))\n",
    "            ax_legend.legend(handles=patches, title=f\"{rank.capitalize()} colors (top {10})\", loc=\"center\")\n",
    "            ax_legend.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stress values depending on the initialization, looks at differences between models for different inits and stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE   \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ----------------------------------------\n",
    "# Assuming global_luts, rank_label_counts, ranks defined as before\n",
    "# ----------------------------------------\n",
    "\n",
    "for data in lookup_data.keys():\n",
    "    print(data)\n",
    "    haus = lookup_data[data]['hausdorff']['distances']\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        metric='precomputed',\n",
    "        random_state=42,\n",
    "        perplexity=17,\n",
    "        init='random'\n",
    "    )\n",
    "    tsne_results = tsne.fit_transform(haus)\n",
    "    \n",
    "    binlookup = lookup_data[data][\"binlookup\"]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(ranks), figsize=(8, 4))\n",
    "    \n",
    "    # Store handles and labels for separate legend plotting\n",
    "    legend_handles = {}\n",
    "\n",
    "    for ax, rank in zip(axes, ranks):\n",
    "        vals = binlookup[rank]\n",
    "        \n",
    "        if rank == \"order\":\n",
    "            # pick top-10 orders by count\n",
    "            top10 = vals.value_counts().index[:10]\n",
    "            lut_full = global_luts[rank]\n",
    "            lut = {o: lut_full[o] for o in top10}\n",
    "            colors = [lut.get(v, (0.8, 0.8, 0.8)) for v in vals]\n",
    "\n",
    "            handles = [\n",
    "                plt.Line2D([], [], marker='o', linestyle='', \n",
    "                           color=lut[o], label=f\"{o} ({rank_label_counts[rank][o]})\")\n",
    "                for o in top10\n",
    "            ]\n",
    "        else:\n",
    "            sorted_cats = vals.value_counts().index.tolist()\n",
    "            lut = global_luts[rank]\n",
    "            colors = [lut[v] for v in vals]\n",
    "            handles = [\n",
    "                plt.Line2D([], [], marker='o', linestyle='',\n",
    "                           color=lut[cls], label=f\"{cls} ({rank_label_counts[rank][cls]})\")\n",
    "                for cls in sorted_cats\n",
    "            ]\n",
    "        \n",
    "        ax.scatter(\n",
    "            tsne_results[:, 0],\n",
    "            tsne_results[:, 1],\n",
    "            c=colors,\n",
    "            s=15,\n",
    "            alpha=0.9,\n",
    "            edgecolor='black',\n",
    "            linewidth=0.2\n",
    "        )\n",
    "        ax.set_title(rank.capitalize(), fontsize=12, fontweight='bold')\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "\n",
    "        # Save handles for later legend plot\n",
    "        legend_handles[rank] = handles\n",
    "    \n",
    "    #fig.suptitle(f\"{data}\", fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, f\"tsne_{data}_.png\"), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Now plot legends separately after main plot\n",
    "    for rank in ranks:\n",
    "        fig_legend, ax_legend = plt.subplots(figsize=(3, max(2, 0.3*len(legend_handles[rank]))))\n",
    "        ax_legend.legend(handles=legend_handles[rank], title=f\"{rank.capitalize()} (top labels)\", loc='center')\n",
    "        ax_legend.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AdvancedNetwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
