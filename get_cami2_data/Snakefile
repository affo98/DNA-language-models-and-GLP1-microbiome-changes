import os
import yaml
import glob

MINSIZE_BINS=250000

#dirs
OUTDIR_RAW = os.path.join(os.getcwd(), "get_cami2_data", "raw_data")
OUTDIR_PROCESSED = os.path.join(os.getcwd(), "get_cami2_data", "processed_data")
OUTDIR_MODEL_RESULTS = os.path.join(os.getcwd(), "get_cami2_data", "model_results")
OUTDIR_CLUSTERS = os.path.join(os.getcwd(), "get_cami2_data", 'clusters')
SRC_DIR = os.path.join(os.getcwd(), "get_cami2_data", "src")
BASE = os.path.join(os.getcwd(), "get_cami2_data")

#dataset, sample and model config
with open(os.path.join(BASE, "config.yml"), "r") as f:
    datasets_model_config = yaml.safe_load(f)

ALL_DATASETS = [d["name"] for d in datasets_model_config["datasets"]]
DATASET = config.get("DATASET", "all")
SAMPLES = {d["name"]: d.get("samples", []) for d in datasets_model_config["datasets"]}
sample_str = ' '.join(SAMPLES.get(DATASET, []))
ALL_MODELS  = [d["name"] for d in datasets_model_config["models"]]
config_model = config.get("MODEL", "all")
MODEL = config_model if config_model != 'all' else ALL_MODELS


#processing flow of snakemake 
config_download = config.get("DOWNLOAD", False)
config_concatenate = config.get("CONCATENATE", False)
config_alignment = config.get("ALIGNMENT", False)
config_checkm2 = config.get("CHECKM2", False)





#bams
#expand(os.path.join(OUTDIR, DATASET, "{sample}_sorted.bam"), sample=[sample for sample in SAMPLES.get(DATASET, [])])


#comebin
#os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "fasta_bins", "comebin"),

#create fasta bins
#os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "all_clusters"),
#expand(os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "fasta_bins", "{model}"), model=MODELS))

#checkm2
#expand(os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "checkm2", "{model}_results"), model=MODEL)



rule all:
    input:
        expand(os.path.join(OUTDIR_RAW, DATASET, "{sample}_contigs.fasta"), sample=[sample for sample in SAMPLES.get(DATASET, [])]),
        expand(os.path.join(OUTDIR_RAW, DATASET, "{sample}_reads.fq.gz"), sample=[sample for sample in SAMPLES.get(DATASET, [])]),
        #concatenate
        os.path.join(OUTDIR_PROCESSED, DATASET, "catalogue.fna.gz"),
        #alignment
        expand(os.path.join(OUTDIR_PROCESSED, DATASET, "{sample}_reads.fq.gz"), sample=[sample for sample in SAMPLES.get(DATASET, [])]),
        #vamb
        #os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "vamb_output"),
        #os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "vamb_postprocess"),
        #os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "fasta_bins", "vamb"),
        #taxvamb
        #os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "metabuli", "metabuli_results"),
        #os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "taxconverter", "result.tsv"),
        #os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "taxvamb_output"),
        #os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "taxvamb_postprocess"),
        #os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "fasta_bins", "taxvamb"),
        #comebin
        #os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "comebin_output"),
        #os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "fasta_bins", "comebin"),
        #checkm2
        #expand(os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "checkm2", "{model}_results"), model=MODEL)
        
        



if config_download:
    rule download_name:
        output:
            contigs=expand(os.path.join(OUTDIR_RAW, DATASET, "{sample}_contigs.fasta"), sample=SAMPLES.get(DATASET, [])),
            reads=expand(os.path.join(OUTDIR_RAW, DATASET, "{sample}_reads.fq.gz"), sample=SAMPLES.get(DATASET, []))
        conda:
            "envs/cami2_processing.yml"
        shell:
            """
            python {SRC_DIR}/get_cami2_data.py {DATASET} {sample_str}
            """


if config_concatenate:
    rule concatenate:
        input:
            expand(os.path.join(OUTDIR_RAW, DATASET, "{sample}_contigs.fasta"), sample=SAMPLES.get(DATASET, []))
        output:
            os.path.join(OUTDIR_PROCESSED, DATASET, "catalogue.fna.gz")
        conda:
            "envs/vamb.yml"
        shell:
            """
            python {SRC_DIR}/concatenate.py {output} {input}
            """

if config_alignment:
    rule alignment:
        input:
            read=os.path.join(OUTDIR_RAW, DATASET, "{sample}_reads.fq.gz"),
            catalogue=os.path.join(OUTDIR_PROCESSED, DATASET, "catalogue.fna.gz")
        output:
            os.path.join(OUTDIR_PROCESSED, DATASET, "{sample}_sorted.bam")
        threads:
            96
        conda:
            "envs/cami2_processing.yml"
        shell:
            """
            strobealign -t {threads} {input.catalogue} {input.read} | samtools sort -o {output}
            """




if MODEL=='vamb':
    rule vamb:
        input:
            catalogue=os.path.join(OUTDIR_PROCESSED, DATASET, "catalogue.fna.gz"),
            bams=expand(os.path.join(OUTDIR_PROCESSED, DATASET, "{sample}_sorted.bam"), sample=SAMPLES.get(DATASET, []))
        output:
            os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "vamb_output")
        conda:
            "envs/cami2_environment.yml"
        shell:
            """
            vamb bin default --outdir {output} --fasta {input.catalogue} --bamfiles {input.bams}
            """

    rule move_cluster_outputs_vamb:
        input:
            model_outputs=os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "vamb_output")
        output:
            cluster_results=directory(os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "vamb_postprocess"))
        conda:
            "envs/cami2_processing.yml"
        shell:
            """
            python {SRC_DIR}/move_cluster_outputs_vamb.py {output.cluster_results} {input.model_outputs}
            """

    rule create_fasta_bins_vamb:
        input:
            catalogue=os.path.join(OUTDIR_PROCESSED, DATASET, "catalogue.fna.gz"),
            cluster_results=os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "vamb_postprocess", "vamb_output_clusters.tsv")
        output:
            dirs=directory(os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "fasta_bins", "vamb"))
        params:
            minsize_bins = MINSIZE_BINS
        conda: 
            "envs/vamb.yml"
        shell:
            """
            python {SRC_DIR}/create_fasta.py {input.catalogue} {input.cluster_results} {params.minsize_bins} {output.dirs}
            """


elif MODEL=='taxvamb':

    rule metabuli:
        input:
            catalogue=os.path.join(OUTDIR_PROCESSED, DATASET, "catalogue.fna.gz")
        output:
            database = os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "metabuli", "gtdb_database"),  
            database_tmp = os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "metabuli", "gtdb_database_tmp"), 
            results = os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "metabuli", "metabuli_results")   
        params:
            seq_mode=1,
            job_id=100

        shell:
            """
            wget https://mmseqs.com/metabuli/metabuli-linux-avx2.tar.gz; tar xvzf metabuli-linux-avx2.tar.gz; export PATH=$(pwd)/metabuli/bin/:$PATH 
            metabuli databases GTDB {output.database} {output.database_tmp}
            metabuli classify --seq-mode {params.seq_mode} {input.catalogue} {output.database}/gtdb {output.results} {params.job_id}
            """
    
    rule taxconverter:
        input:
            input_dir = directory(os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "metabuli", "metabuli_results"))
        output:
            result = os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "taxconverter", "result.tsv")
        conda:
            "envs/taxconverter.yml"
        params:
            lineage_zip="https://github.com/RasmussenLab/taxconverter/raw/7f5ff980612dc59d3290b5ddfe97eb814e96c42f/data/lineage.zip",
            lineage_dir="taxconverter/data"
        shell:
            """
            git clone git@github.com:RasmussenLab/taxconverter.git
            cd taxconverter
            pip install -e .

            curl -L -o {params.lineage_dir}/lineage.zip "{params.lineage_zip}"
            unzip -o {params.lineage_dir}/lineage.zip -d {params.lineage_dir}

            taxconverter metabuli -c {input.input_dir}/100_classifications.tsv -r {input.input_dir}/100_report.tsv -o {output.result}
            """

    rule taxvamb:
        input:
            catalogue=os.path.join(OUTDIR_PROCESSED, DATASET, "catalogue.fna.gz"),
            bams=expand(os.path.join(OUTDIR_PROCESSED, DATASET, "{sample}_sorted.bam"), sample=SAMPLES.get(DATASET, [])),
            taxonomy=os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "taxconverter", "result.tsv")
        output:
            os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "taxvamb_output")
        conda:
            "envs/cami2_environment.yml"
        shell:
            """
            vamb bin taxvamb --outdir {output} --fasta {input.catalogue} --bamfiles {input.bams} --taxonomy {input.taxonomy}
            """


    rule move_cluster_outputs_taxvamb:
        input:
            model_outputs=os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "taxvamb_output")
        output:
            cluster_results=directory(os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "taxvamb_postprocess"))
        conda:
            "envs/cami2_processing.yml"
        shell:
            """
            python {SRC_DIR}/move_cluster_outputs_vamb.py {output.cluster_results} {input.model_outputs}
            """

    rule create_fasta_bins_taxvamb:
        input:
            catalogue=os.path.join(OUTDIR_PROCESSED, DATASET, "catalogue.fna.gz"),
            cluster_results=os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "taxvamb_postprocess", "vamb_output_clusters.tsv")
        output:
            dirs=directory(os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "fasta_bins", "taxvamb"))
        params:
            minsize_bins = MINSIZE_BINS
        conda: 
            "envs/vamb.yml"
        shell:
            """
            python {SRC_DIR}/create_fasta.py {input.catalogue} {input.cluster_results} {params.minsize_bins} {output.dirs}
            """



elif MODEL == 'comebin':

    rule comebin:
        input:
            catalogue=expand(os.path.join(OUTDIR_PROCESSED, DATASET, "catalogue.fna.gz")),
            bams=expand(os.path.join(OUTDIR_PROCESSED, DATASET, "{sample}_sorted.bam"), sample=SAMPLES.get(DATASET, []))
        output:
            os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "comebin_output")
        params:
            views=6,
            threads=48
        conda:
            "envs/comebin_environment.yml"
        shell:
            """
            bash run_comebin.sh -a {input.catalogue} -p {input.bams} -o {output} -n {params.views} -t {params.threads}
            """

    rule postprocess_cluster_outputs_comebin:
        input:
            model_outputs=os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "comebin_output", "comebin_res", "comebin_res_bins")
        output:
            cluster_fasta=directory(os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "fasta_bins", "comebin"))
        params:
            minsize_bins = 250000
        conda:
            "envs/cami2_processing.yml"
        shell:
            """
            python {SRC_DIR}/postprocess_cluster_outputs_comebin.py {output.cluster_fasta} {input.model_outputs} {params.minsize_bins}
            """




if config_checkm2:
    rule checkm2:
        input:
            fasta_bins=expand(os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "fasta_bins", "{model}"), model=MODEL)
        output:
            output=directory(expand(os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "checkm2", "{model}_results"), model=MODEL))
        conda:
            "envs/checkm2.yml"
        threads:
            128
        shell:
            """
            checkm2 predict --threads {threads} --input {input.fasta_bins} --output-directory {output.output}
            """







# rule semibin:
#     input:
#         catalogue=expand(os.path.join(OUTDIR_PROCESSED, DATASET, "catalogue.fna.gz")),
#         bams=expand(os.path.join(OUTDIR_PROCESSED, DATASET, "{sample}_sorted.bam"), sample=SAMPLES.get(DATASET, []))
#     output:
#         os.path.join(OUTDIR_MODEL_RESULTS, DATASET, "semibin_output")
#     conda:
#         "envs/semibin_environment.yml"
#     shell:
#         """
        
#         """







# rule concatenate_process_semibin:
#     input:
#         os.path.join(OUTDIR, DATASET, "catalogue.fna.gz")
#     output:
#         os.path.join(OUTDIR, DATASET, "semibin/catalogue_semibin.fna")
#     conda:
#         "envs/cami2_environment.yml"
#     shell:
#         """
#         zcat {input} | sed -E 's/([0-9]+)([A-Za-z])/\\1:\\2/' > {output} 
#         """


# rule bam_process_semibin:
#     input:
#         bam=os.path.join(OUTDIR, DATASET, "{sample}_sorted.bam")
#     output:
#         modified_bam=os.path.join(OUTDIR, DATASET, "semibin/{sample}_sorted_semibin.bam")
#     conda:
#         "envs/cami2_environment.yml"
#     shell:
#         """
#         samtools view -H {input.bam} | \\
#         sed -E 's/([0-9]+)([A-Za-z0-9]+)/\\1:\\2/' | \\
#         samtools reheader - {input.bam} > {output.modified_bam}
#         """

#rule_all
    #input:
        #os.path.join(OUTDIR, DATASET, "semibin/catalogue_semibin.fna")
        #expand(os.path.join(OUTDIR, DATASET, "semibin/{sample}_sorted_semibin.bam"), sample=[sample for sample in SAMPLES.get(DATASET, [])])





    

